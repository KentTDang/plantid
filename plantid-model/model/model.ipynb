{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f9375e-b697-4256-b5b1-05c1a4e488ed",
   "metadata": {},
   "source": [
    "# Loading data from preprocessed pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db562f6b-6613-458f-ad13-da925dba80c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open the pickle file in read-binary mode\n",
    "with open('..//model-data/preprocessing/train-val-sets/train_val_split.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# storing data\n",
    "images_train = data['images_train']\n",
    "images_val = data['images_val']\n",
    "labels_train = data['labels_train']\n",
    "labels_val = data['labels_val']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5ef8ef-a00b-4d0d-82e5-3ae106517c12",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1fd5a1a-be94-412d-974a-bc90e422728b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, Sequential\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Rescaling(scale=1.0/255, input_shape=(256, 256, 3)),\n",
    "    \n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(39, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d08a7-a671-4b3e-81b5-1d820be60720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac6fb4d-e68e-4102-b838-14d596af7434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5489030-dea0-4108-9939-43c304a1fff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587f40a-70d9-4f42-95b9-15e6ef9a5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, Sequential\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(256, 256, 3)),\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(16, activation='softmax'),\n",
    "    layers.Dense(39, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19effef-47b6-40ce-930d-4de3d360b472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48c30ab9-fb5f-4918-be39-b7237d06b0ef",
   "metadata": {},
   "source": [
    "# Compling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d626e483-0ac1-4fbd-b81c-52071a3df8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233db3f-7f10-4127-9705-b24888ad6fd1",
   "metadata": {},
   "source": [
    "# Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18bd3939-885c-4cd0-9dd3-29a8696e64a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737827764.478877   25262 service.cc:145] XLA service 0x7815c8005150 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1737827764.478902   25262 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2025-01-25 17:56:04.492222: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-25 17:56:04.553003: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737827765.168017   25326 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_450', 544 bytes spill stores, 544 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/440\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.1202 - loss: 141.8384 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737827766.816689   25262 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - accuracy: 0.3632 - loss: 35.8232\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.5467 - loss: 2.6793\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.6158 - loss: 1.7074\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9320 - loss: 0.2590\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9560 - loss: 0.1578\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.9411 - loss: 0.2120\n"
     ]
    }
   ],
   "source": [
    "# sliding window model training (to handle batching due to tensorflow gpu mem errors)\n",
    "\n",
    "for w in range(2):\n",
    "    # calculating a third of the data size\n",
    "    third_of_data = len(images_train) // 3\n",
    "    HR_size = third_of_data\n",
    "    LR_size = 0\n",
    "    \n",
    "    for i in range(3):\n",
    "        #print(LR_size, HR_size)\n",
    "        images_train_third = images_train[LR_size:HR_size]\n",
    "        labels_train_third = labels_train[LR_size:HR_size]\n",
    "    \n",
    "        model.fit(images_train_third, labels_train_third, epochs=1)\n",
    "        \n",
    "        LR_size += third_of_data;\n",
    "        HR_size += third_of_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d72bc-c6ab-4a2b-890b-e53a2322dfd4",
   "metadata": {},
   "source": [
    "# Validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75c35cfc-fbce-4d00-b62c-6150f7504f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m331/331\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step\n",
      "Validation Accuracy: 0.6474765647192501\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# converting one hot encoded labels to class indices\n",
    "real_labels = np.argmax(labels_val, axis=1)\n",
    "\n",
    "# predict on the validation set\n",
    "predictions = model.predict(images_val)\n",
    "\n",
    "# converting predictions from one hot encoded probabiliti|es to class indices\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# comparing predictions with the real labels\n",
    "print(\"Validation Accuracy:\", accuracy_score(real_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf0cee5-773b-4142-9735-b38db42cd7e7",
   "metadata": {},
   "source": [
    "# [TESTING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2791f-5769-4a37-97ed-bd47e840e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_max(arr):\n",
    "    result = np.zeros_like(arr)\n",
    "    result[np.argmax(arr)] = 1\n",
    "    return result\n",
    "\n",
    "print(one_hot_max(predictions[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80111a67-cfb2-41ca-94c1-86e5e3baca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_val[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
